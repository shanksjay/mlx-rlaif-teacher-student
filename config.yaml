model:
  base_model: Qwen/Qwen2.5-Coder-3B-Instruct
  use_4bit: true
  use_flash_attention: true
  max_length: 512
  device_map: auto
  use_safetensors: true
  low_cpu_mem_usage: true
teacher:
  provider: anthropic
  model_name: claude-3-5-haiku-20241022
  api_key_env: ANTHROPIC_API_KEY
  temperature: 0.7
  max_tokens: 512
training:
  output_dir: ./checkpoints
  resume_from_checkpoint: null
  num_epochs: 7
  batch_size: 4
  gradient_accumulation_steps: 50
  generation_accumulation_batches: 1
  learning_rate: 6.400000000000001e-05
  optimizer: adamw
  warmup_steps: 300
  save_steps: 500
  save_every_epochs: 1
  save_every_batches: 0
  eval_steps: 250
  logging_steps: 50
  max_grad_norm: 1.0
  weight_decay: 0.0
  lr_scheduler_type: cosine
  save_total_limit: 3
rlaif:
  reward_weight: 1.5625
  kl_penalty: 0.108375
  reward_threshold: 0.0
  beta: 0.1
  top_k: 50
  top_p: 0.95
  num_samples_per_prompt: 4
  generation_temperature: 1.0285000000000002
  curriculum_learning: true
  reward_bonuses: false
  use_advantage_normalization: true
  advantage_baseline_ema_alpha: 0.9
  use_frozen_reference_for_kl: true
  use_tiered_scoring: true
  heuristic_score_threshold: 0.3
  truncate_prompt_for_scoring: true
  prompt_context_chars: 200
  move_rubric_to_system_prompt: true
  use_lora: true
  use_qlora: false
  lora_r: 16
  lora_alpha: 32
  lora_dropout: 0.05
data:
  train_file: ./data/train.jsonl
  eval_file: ./data/eval.jsonl
  languages:
  - python
  - cpp
  - rust
  max_train_samples: null
  max_eval_samples: 100
evaluation:
  metrics:
  - code_quality
  - correctness
  - readability
  - efficiency
  reward_threshold: 0.7
logging:
  use_tensorboard: true
  tensorboard_dir: ./logs/tensorboard
  use_wandb: false
  wandb_project: code-rlaif
  log_level: INFO
  save_json_summaries: true
  json_summaries_dir: ./logs/json_summaries
  baseline_eval_batches: 1
  tensorboard_batch_interval: 1
  monitoring_interval_s: 5
  system_monitor_step_mode: batch
  health_check_enabled: true
  health_check_interval_batches: 5
  health_check_grace_batches: 3
  epoch_health_check_enabled: true
  within_epoch_trend_detection_enabled: true
  health_check_gen_bottleneck_pct: 85
  health_check_gen_target_tps: 6.0
  health_check_fragmentation_enabled: true
  health_check_mps_fragmentation_gb: 10.0
  health_check_mlx_cache_gb: 3.0
  health_check_fragmentation_growth_gb: 0.75
  health_check_trigger_gc_on_fragmentation: true
  health_check_gc_cooldown_batches: 10
  gpu_utilization_mode: memory_proxy
hardware:
  use_mps: true
  mixed_precision: bf16
  dataloader_num_workers: 4
  mps_allocator_warmup_gb: 0.0
  save_mlx_format: true
  mlx_quantization: q8_bit
  use_mlx_for_generation: true
  require_mlx_for_generation: true
  allow_4bit_on_mps: false
  reload_mlx_from_latest_checkpoint: false
  mlx_metal_cache_limit_gb: 1.0
  use_mlx_generation_worker: true
  lora_mlx_sync_enabled: true
  lora_mlx_sync_every_optimizer_steps: 1
  mlx_generation_worker_timeout_s: 240
  mlx_model_path: ./mlx_model/q4
  use_unsloth: false
  unsloth_dtype: bf16
  unsloth_max_seq_length: null
huggingface:
  upload_to_hub: false
  repo_id: mlx-community/code-rlaif
  hf_token_env: HUGGINGFACE_TOKEN
  upload_quantized: true
  private: false
  upload_datasets: true
  dataset_repo_id: mlx-community/code-rlaif-dataset
  save_datasets_locally: true
  dataset_output_dir: ./datasets
